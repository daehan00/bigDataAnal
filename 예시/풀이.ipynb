{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:16.625274Z",
     "start_time": "2025-06-18T14:00:15.696693Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/mtcars.csv\")\n",
    "print(df['qsec'].count())\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[[\"qsec\"]] = scaler.fit_transform(df[[\"qsec\"]])\n",
    "print(df[df[\"qsec\"] > 0.5][\"qsec\"].count())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "9\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:16.631044Z",
     "start_time": "2025-06-18T14:00:16.626092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/basic1.csv\")\n",
    "df_70 = df.loc[:len(df)*0.7-1]\n",
    "\n",
    "# print(dir(pd.DataFrame))\n",
    "df = df.sort_values(by=[\"f5\"], ascending=False).reset_index()\n",
    "val = df[\"f5\"].loc[9]\n",
    "df.loc[:9, \"f5\"] = val\n",
    "\n",
    "print(df[df[\"age\"] >= 80][\"f5\"].mean())\n",
    "\n",
    "std_p = df_70[\"f1\"].std()\n",
    "med = df_70[\"f1\"].median()\n",
    "std_a = df_70[\"f1\"].fillna(med).std()\n",
    "\n",
    "print(abs(std_a - std_p))\n",
    "\n",
    "age = df[\"age\"]\n",
    "m = age.mean()\n",
    "std = age.std()\n",
    "\n",
    "result = 0\n",
    "for i in age:\n",
    "    if m - std*1.5 <= i <= m + std*1.5:\n",
    "        continue\n",
    "    result += i\n",
    "print(result)"
   ],
   "id": "80c12cc9ebc4bfc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.49774712521738\n",
      "3.2965018033960725\n",
      "473.5\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:16.694575Z",
     "start_time": "2025-06-18T14:00:16.631623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def exam_data_load(df, target, id_name=\"\", null_name=\"\"):\n",
    "    if id_name == \"\":\n",
    "        df = df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "        id_name = 'id'\n",
    "    else:\n",
    "        id_name = id_name\n",
    "    \n",
    "    if null_name != \"\":\n",
    "        df[df == null_name] = np.nan\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=2021)\n",
    "    \n",
    "    y_train = X_train[[id_name, target]]\n",
    "    X_train = X_train.drop(columns=[target])\n",
    "\n",
    "    \n",
    "    y_test = X_test[[id_name, target]]\n",
    "    X_test = X_test.drop(columns=[target])\n",
    "    return X_train, X_test, y_train, y_test "
   ],
   "id": "ed3267546a51abe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:17.430743Z",
     "start_time": "2025-06-18T14:00:16.695635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/2_Train.csv\")\n",
    "train, test, y, y_test = exam_data_load(df, target='Reached.on.Time_Y.N', id_name='ID')\n",
    "\n",
    "train.drop(\"ID\", axis=1, inplace=True)\n",
    "y = y[\"Reached.on.Time_Y.N\"]\n",
    "\n",
    "id = test[\"ID\"].reset_index(drop=True)\n",
    "test.drop(\"ID\", axis=1, inplace=True)\n",
    "# train.info()\n",
    "# y.info()\n",
    "# print(train.shape, y.shape)\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import sklearn\n",
    "print(sklearn.ensemble.__all__)\n",
    "c_col = train.select_dtypes(include=\"object\").columns\n",
    "n_col = train.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "# for col in c_col:\n",
    "#     a = set(train[col].unique()) - set(test[col].unique())\n",
    "#     b = set(train[col].unique()) - set(test[col].unique())\n",
    "#     if not a and not b:\n",
    "#         continue\n",
    "#     else:\n",
    "#         print(a, b)\n",
    "\n",
    "# for col in n_col:\n",
    "#     print(col, train[col].describe())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for col in c_col:\n",
    "    train[col] = encoder.fit_transform(train[col])\n",
    "    test[col] = encoder.transform(test[col])\n",
    "    \n",
    "train[n_col] = scaler.fit_transform(train[n_col])\n",
    "test[n_col] = scaler.transform(test[n_col])\n",
    "\n",
    "train, val, y, val_y = train_test_split(train, y, test_size=0.15, random_state=42)\n",
    "\n",
    "models = [AdaBoostClassifier(random_state=40), GradientBoostingClassifier(random_state=42)]\n",
    "for model in models:\n",
    "    model.fit(train, y)\n",
    "    \n",
    "    y_pred = model.predict(val)\n",
    "    ras = roc_auc_score(y_pred, val_y)\n",
    "    acc = accuracy_score(y_pred, val_y)\n",
    "    \n",
    "    print(ras, acc)\n",
    "\n",
    "test_prob = models[1].predict_proba(test)[:,1]\n",
    "# print(test_prob.shape, id.shape)\n",
    "result = pd.DataFrame({\"ID\":id, \"Reached.on.Time_Y.N\":test_prob})\n",
    "print(result)\n"
   ],
   "id": "b93f7d6c3b4629fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BaseEnsemble', 'RandomForestClassifier', 'RandomForestRegressor', 'RandomTreesEmbedding', 'ExtraTreesClassifier', 'ExtraTreesRegressor', 'BaggingClassifier', 'BaggingRegressor', 'IsolationForest', 'GradientBoostingClassifier', 'GradientBoostingRegressor', 'AdaBoostClassifier', 'AdaBoostRegressor', 'VotingClassifier', 'VotingRegressor', 'StackingClassifier', 'StackingRegressor', 'HistGradientBoostingClassifier', 'HistGradientBoostingRegressor']\n",
      "0.6738776259613127 0.6606060606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhkim/miniconda3/envs/test_env/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7238077923737039 0.6833333333333333\n",
      "        ID  Reached.on.Time_Y.N\n",
      "0     4733             0.453148\n",
      "1     2040             0.993927\n",
      "2     5114             0.404309\n",
      "3     2361             0.993328\n",
      "4     5996             0.369141\n",
      "...    ...                  ...\n",
      "2195   360             0.762136\n",
      "2196  7832             0.264149\n",
      "2197  9754             0.379545\n",
      "2198  3751             0.444578\n",
      "2199  4414             0.405841\n",
      "\n",
      "[2200 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:17.438660Z",
     "start_time": "2025-06-18T14:00:17.431462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/t1-data2.csv\", index_col = \"year\")\n",
    "\n",
    "med = df.loc[\"2022년\"].median()\n",
    "cnt = 0\n",
    "for i in df.loc[\"2022년\"]:\n",
    "    if i > med:\n",
    "        cnt += 1\n",
    "print(cnt)\n",
    "\n",
    "df = pd.read_csv(\"../data/t1-data1.csv\")\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index()\n",
    "val = df.loc[:int(len(df)*0.6)][\"f1\"].quantile(0.75)\n",
    "print(int(val - (val % 1)))\n",
    "\n",
    "df = pd.read_csv(\"../data/t1-data1.csv\")\n",
    "print(df.isna().sum().sort_values().index[-1])"
   ],
   "id": "72315bed37efccbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "77\n",
      "f1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:17.652629Z",
     "start_time": "2025-06-18T14:00:17.439360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"../data/t2-1-train.csv\")\n",
    "test = pd.read_csv(\"../data/t2-1-test.csv\")\n",
    "\n",
    "y = train[\"TravelInsurance\"]\n",
    "train = train.drop([\"TravelInsurance\", \"id\"], axis=1)\n",
    "\n",
    "train[\"AnnualIncome\"] = train[\"AnnualIncome\"].fillna(train[\"AnnualIncome\"].median())\n",
    "\n",
    "id = test.pop(\"id\").reset_index(drop=True)\n",
    "test[\"AnnualIncome\"] = test[\"AnnualIncome\"].fillna(train[\"AnnualIncome\"].median())\n",
    "# print(train.shape, test.shape, id.shape, y.shape)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "c_col = train.select_dtypes(include=\"object\").columns\n",
    "n_col = train.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train[n_col] = scaler.fit_transform(train[n_col])\n",
    "test[n_col] = scaler.transform(test[n_col])\n",
    "\n",
    "map_col = []\n",
    "for col in c_col:\n",
    "    a = set(train[col].unique())\n",
    "    b = set(test[col].unique())\n",
    "\n",
    "    if a == b:\n",
    "        map_col.append(col)\n",
    "        continue\n",
    "    # print(col, a, b)\n",
    "# print(train.shape, test.shape)\n",
    "\n",
    "# print(help(pd.get_dummies))\n",
    "train = pd.get_dummies(train, columns=map_col, drop_first=True)\n",
    "test = pd.get_dummies(test, columns=map_col, drop_first=True)\n",
    "train = pd.get_dummies(train, columns=[\"Employment Type\"])\n",
    "test = pd.get_dummies(test, columns=[\"Employment Type\"], drop_first=True)\n",
    "\n",
    "# print(set(train.columns) - set(test.columns))\n",
    "# print(set(test.columns) - set(train.columns))\n",
    "\n",
    "train, val, y, y_val = train_test_split(train, y, test_size=0.15, random_state=4)\n",
    "# print(train.shape, val.shape, y.shape, y_val.shape)\n",
    "\n",
    "models = [GradientBoostingClassifier(random_state=42), AdaBoostClassifier(random_state=42), RandomForestClassifier(random_state=42)]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train, y)\n",
    "    predict = model.predict(val)\n",
    "    ras = roc_auc_score(predict, y_val)\n",
    "    ac = accuracy_score(predict, y_val)\n",
    "    print(ras, ac)\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "model.fit(train, y)\n",
    "result = pd.DataFrame({\"id\":id, \"TravelInsurance\":model.predict_proba(test)[:,1]})\n",
    "print(result.head())\n"
   ],
   "id": "33ee85a20bd19c8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850204081632653 0.8348214285714286\n",
      "0.8351992536318805 0.8080357142857143\n",
      "0.7573669918535654 0.78125\n",
      "   id  TravelInsurance\n",
      "0   0         0.342776\n",
      "1   1         0.174348\n",
      "2   2         0.027579\n",
      "3   3         0.952573\n",
      "4   4         0.038030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhkim/miniconda3/envs/test_env/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:17.657173Z",
     "start_time": "2025-06-18T14:00:17.653088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/high_blood_pressure.csv\")\n",
    "\n",
    "df[\"target\"] = df[\"bp_post\"] - df[\"bp_pre\"]\n",
    "print(round(df[\"target\"].mean(), 2))\n",
    "\n",
    "from scipy import stats\n",
    "# print(help(stats.ttest_rel))\n",
    "t, p = stats.ttest_rel(df[\"bp_post\"], df[\"bp_pre\"], alternative='less')\n",
    "print(round(t, 4))\n",
    "print(round(p, 4))"
   ],
   "id": "59d94a2316fddcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.12\n",
      "-3.0002\n",
      "0.0016\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:17.937124Z",
     "start_time": "2025-06-18T14:00:17.657659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/Titanic_train.csv\")\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "# print(dir(pd))\n",
    "\n",
    "df_group = pd.crosstab(df[\"Sex\"], df[\"Survived\"])\n",
    "result = chi2_contingency(df_group)\n",
    "print(round(result.statistic, 3))\n",
    "\n",
    "from statsmodels.api import Logit\n",
    "formula = \"Survived ~ Sex + SibSp + Parch + Fare\"\n",
    "# print(dir(Logit.from_formula))\n",
    "result = Logit.from_formula(formula, df).fit()\n",
    "print(round(result.params[\"Parch\"], 3))\n",
    "\n",
    "odds = np.exp(result.params[\"SibSp\"])\n",
    "print(round(odds, 3))"
   ],
   "id": "64798dbabf4dd255",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260.717\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482065\n",
      "         Iterations 6\n",
      "-0.201\n",
      "0.702\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:17.999753Z",
     "start_time": "2025-06-18T14:00:17.937717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/basic1.csv\")\n",
    "\n",
    "val = abs(df[\"age\"].quantile(0.75) - df[\"age\"].quantile(0.25))\n",
    "print(int(val - val % 1))\n",
    "\n",
    "df = pd.read_csv(\"../data/fb.csv\")\n",
    "# df.info()\n",
    "df[\"target\"] = (df[\"loves\"] + df[\"wows\"]) / df[\"reactions\"]\n",
    "cond1 = df[\"target\"] > 0.4\n",
    "cond2 = df[\"target\"] < 0.5\n",
    "cond3 = df[\"type\"] == \"video\"\n",
    "\n",
    "print(len(df[cond1 & cond2 & cond3]))\n",
    "\n",
    "df = pd.read_csv(\"../data/nf.csv\")\n",
    "df.dropna(subset=[\"date_added\"], inplace=True)\n",
    "df[\"year\"] = df[\"date_added\"].str.split(\" \").str[-1].str.strip()\n",
    "df[\"month\"] = df[\"date_added\"].str.split(\" \").str[0].str.strip()\n",
    "\n",
    "# df.head()\n",
    "cond1 = df[\"year\"] == \"2018\"\n",
    "cond2 = df[\"month\"] == \"January\"\n",
    "cond3 = df[\"country\"] == \"United Kingdom\"\n",
    "print(len(df[cond1 & cond2 & cond3]))"
   ],
   "id": "fa3e036dd0cdb045",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "90\n",
      "6\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:19.219476Z",
     "start_time": "2025-06-18T14:00:18.001333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "y = train.pop(\"Segmentation\")\n",
    "\n",
    "train = train.drop(\"ID\", axis=1)\n",
    "id = test.pop(\"ID\").reset_index(drop=True)\n",
    "\n",
    "# print(train.shape, y.shape, test.shape)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "c_col = train.select_dtypes(include=\"object\").columns\n",
    "n_col = train.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "# for col in c_col:\n",
    "#     a = set(train[col])\n",
    "#     b = set(test[col])\n",
    "#     if a != b:\n",
    "#         print(a, b)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train[n_col] = scaler.fit_transform(train[n_col])\n",
    "test[n_col] = scaler.transform(test[n_col])\n",
    "\n",
    "for col in c_col:\n",
    "    train[col] = encoder.fit_transform(train[col])\n",
    "    test[col] = encoder.transform(test[col])\n",
    "    \n",
    "train, val, y, y_val = train_test_split(train, y, test_size=0.15, random_state=42)\n",
    "# print(train.shape, y.shape, val.shape, y_val.shape)\n",
    "\n",
    "models = [RandomForestClassifier(random_state=42), AdaBoostClassifier(random_state=42), GradientBoostingClassifier(random_state=42)]\n",
    "\n",
    "# print(help(f1_score))\n",
    "for model in models:\n",
    "    model.fit(train, y)\n",
    "    pred = model.predict(val)\n",
    "    f1_s = f1_score(pred, y_val, average=\"macro\")\n",
    "    acc = accuracy_score(pred, y_val)\n",
    "    print(f1_s, acc)\n",
    "\n",
    "result = pd.DataFrame({\"ID\":id, \"Segmentation\":model.predict(test)})\n",
    "print(result)"
   ],
   "id": "f8f600959ee09728",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4989795481593646 0.508\n",
      "0.4971265300879215 0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhkim/miniconda3/envs/test_env/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5288451378801535 0.544\n",
      "          ID  Segmentation\n",
      "0     458989             1\n",
      "1     458994             2\n",
      "2     459000             3\n",
      "3     459003             2\n",
      "4     459005             2\n",
      "...      ...           ...\n",
      "2149  467950             1\n",
      "2150  467954             4\n",
      "2151  467958             1\n",
      "2152  467961             2\n",
      "2153  467968             4\n",
      "\n",
      "[2154 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:19.223295Z",
     "start_time": "2025-06-18T14:00:19.220172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/basic1.csv\")\n",
    "\n",
    "age = df[\"age\"]\n",
    "\n",
    "result = 0\n",
    "cnt = 0\n",
    "for i in age:\n",
    "    if i % 1 != 0:\n",
    "        result += np.floor(i) + np.ceil(i) + np.trunc(i)\n",
    "        cnt += 1\n",
    "print(result / cnt)"
   ],
   "id": "50f6edd6105bbc6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.5\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:19.226882Z",
     "start_time": "2025-06-18T14:00:19.223813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/basic1.csv\")\n",
    "\n",
    "# print(df.isna().sum() / len(df) * 100)\n",
    "\n",
    "df.drop(\"f3\", axis=1, inplace=True)\n",
    "\n",
    "df_map = df.groupby(\"city\")[\"f1\"].median()\n",
    "# print(help(df.fillna))\n",
    "df[\"f1\"] = df[\"f1\"].fillna(df[\"city\"].map(df_map))\n",
    "print(df[\"f1\"].mean())"
   ],
   "id": "a891f593355b7a5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.52\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:00:19.232240Z",
     "start_time": "2025-06-18T14:00:19.227340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/t2-1-train.csv\")\n",
    "df.info()\n",
    "sp_s = df[\"AnnualIncome\"].skew()\n",
    "sp_k = df[\"AnnualIncome\"].kurt()\n",
    "df[\"AnnualIncome_1\"] = np.log1p(df[\"AnnualIncome\"])\n",
    "\n",
    "sp_l_s = df[\"AnnualIncome_1\"].skew()\n",
    "sp_l_k = df[\"AnnualIncome_1\"].kurt()\n",
    "print(sp_s, sp_k, sp_l_s, sp_l_k)"
   ],
   "id": "82a4f11b948391eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   1490 non-null   int64  \n",
      " 1   Age                  1490 non-null   int64  \n",
      " 2   Employment Type      1490 non-null   object \n",
      " 3   GraduateOrNot        1490 non-null   object \n",
      " 4   AnnualIncome         1486 non-null   float64\n",
      " 5   FamilyMembers        1490 non-null   int64  \n",
      " 6   ChronicDiseases      1490 non-null   int64  \n",
      " 7   FrequentFlyer        1490 non-null   object \n",
      " 8   EverTravelledAbroad  1490 non-null   object \n",
      " 9   TravelInsurance      1490 non-null   int64  \n",
      "dtypes: float64(1), int64(5), object(4)\n",
      "memory usage: 116.5+ KB\n",
      "0.08269262230546265 -1.0113940872313758 -0.588070073691044 -0.5968175663162993\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
